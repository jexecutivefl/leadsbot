Technical Architecture (Stack & Infrastructure)
We will implement the solution using a modern serverless architecture to maximize scalability and minimize maintenance and cost. Here is an overview of the planned tech stack and how the components will interact: Frontend:
Web App: Built with Next.js (React) – this provides a robust framework for building the agent dashboard, with server-side rendering for fast performance. Agents can log in to view leads, transcripts, and reports. Next.js also allows easy deployment on AWS Amplify Hosting or Vercel. We’ll use this for the main dashboard and settings UI.
Mobile App: Built with React Native (likely using Expo for ease of development). The mobile app will share a lot of code and design elements with the web (thanks to React) but tailored for a smaller screen and push notification integration. It will be used by agents on the go to get real-time chat updates and respond if needed. Having a cross-platform mobile app ensures agents can always stay connected with their AI assistant’s progress.
Shared Code & Repository: We plan a monorepo structure where the Next.js app, React Native app, and Amplify backend code all live together. AWS Amplify Gen 2 supports this kind of setup, allowing us to reuse models and configuration across platforms
reddit.com
. This means the data models and API definitions (written in TypeScript for Amplify) act as the single source of truth and generate code for frontend (via Amplify codegen) as well as set up the cloud resources. The monorepo approach simplifies integration and ensures consistency between web and mobile clients.
Backend (AWS Amplify Gen 2):
We will leverage AWS Amplify (Generation 2) as our backend-as-a-service. Amplify Gen 2 offers a “fullstack TypeScript” development experience
docs.amplify.aws
, letting us define cloud resources in code (in our repo) and deploy easily. Key AWS services used under the hood:
Authentication: Amazon Cognito User Pools for managing user accounts (agents, team admins). Amplify makes it straightforward to set up sign-up/sign-in, secure token-based auth, and even social login if needed. Each agent will be a Cognito user; we can use attributes or groups to mark roles (e.g., an “agent” group, “admin” group). This gives us a secure identity layer and integrates with the API for row-level security.
API & Business Logic: AWS AppSync (GraphQL API) will serve as the core data API. We’ll design a GraphQL schema for our data models: e.g., Lead, ConversationMessage, Appointment, AgentProfile, etc. Amplify will generate resolvers to store/fetch data in DynamoDB. GraphQL is great here because it allows real-time subscriptions – we can push updates to clients (for instance, when a new message arrives from a lead, the agent’s app can get it live if they are viewing that conversation). It also seamlessly integrates with the Amplify client libraries on React/React Native for data management. All access to data goes through AppSync, which will enforce auth rules (like only the lead’s owner can read the conversation). We will use GraphQL @auth directives (Amplify’s auth rules) to implement multi-tenancy and per-user data isolation
docs.amplify.aws
. For example, type Lead @model @auth(rules: [{ allow: owner, ownerField: "agentId" }]) ensures only the agent who owns the lead can read/write it (and maybe allow an admin role to read all). AppSync will interface with DynamoDB for most data, and potentially Lambda for certain operations.
Database: Amazon DynamoDB (a serverless NoSQL database) will store our application data. Each table (or a single multi-entity table as per Amplify’s default) will hold the records for leads, messages, etc. DynamoDB is chosen for its scalability (it can handle large volumes of events like messages) and its integration with Amplify’s GraphQL (Amplify will auto-generate the table structures and resolvers). We’ll likely use a single-table design with composite keys to isolate tenants and enable querying an agent’s items efficiently
blog.logrocket.com
blog.logrocket.com
. For example, partition key could be agent or tenant ID, sort key includes item type and timestamp. This way, all leads for an agent can be queried quickly, and multi-tenant data separation is naturally enforced by partition.
Serverless Functions: AWS Lambda functions will be used for custom backend logic that cannot be done directly in AppSync resolvers. We anticipate using Lambdas for:
Integrations: E.g., a function to call external APIs like Zillow or FollowUpBoss to pull in new leads (could be triggered on a schedule or via webhook), or to send data out.
Communication Actions: When the AI needs to send an SMS or email, we might call a Lambda that invokes Twilio’s API or Amazon Simple Email Service, etc. This keeps third-party secrets secure (not exposed to frontend) and handles the HTTP requests. Amplify supports adding functions easily, and we can secure them with IAM.
AI Chatbot Calls: We will likely have a Lambda that serves as the ChatGPT proxy. The flow: our AppSync can invoke a Lambda (perhaps via a direct Lambda resolver or via AWS EventBridge on a new message) that sends the conversation context to OpenAI’s API and gets the AI’s reply. This Lambda could also implement any prompt engineering or system instructions (e.g., ensuring the AI stays on script or extracts key info). Using Lambda for AI calls decouples the front-end from directly calling OpenAI, adding security and allowing future swap-out to another model or provider.
Webhook Endpoints: For handling incoming messages/calls: e.g., Twilio will send an HTTP webhook when a lead replies via SMS or when a call comes in. We can expose a Lambda behind Amazon API Gateway (or use the new Amplify Function URL feature) to receive these webhooks. The Lambda will parse the incoming message, insert it into our system (e.g., as a new ConversationMessage in DynamoDB), which then triggers the AppSync subscription to update the client and also triggers the AI response flow. This real-time loop connects external communications back into our AI brain.
Scheduling & Misc: Perhaps use Lambda (with EventBridge Scheduler) to implement drip follow-ups: e.g., schedule a Lambda to run X days later to send a follow-up if the lead went cold. Amplify makes it possible to set up periodic functions as needed.
Storage: If we need to store any files, e.g., call recordings or perhaps images (if an agent wants to send a listing photo via the AI), we have Amazon S3 via Amplify Storage. Initially, likely not needed beyond maybe storing conversation logs as text files for backup or compliance. Dynamo records plus CloudWatch logs for Lambda should suffice. If voice calls are recorded (for QA), those could be stored in S3.
AI Services: Aside from OpenAI’s API (which we’ll use via Lambda as mentioned), we also have the option of using AWS AI services: Amazon Transcribe (for speech-to-text on calls), Amazon Polly (for text-to-speech voice). These integrate well with Lambda code (boto3 SDK in Python for instance). We will weigh cost and quality – e.g., Google’s speech API or Twilio’s built-in speech might be alternatives. But staying within AWS for those parts could simplify architecture (especially if using AWS Connect or Amazon Lex for voice bots). However, Amazon Lex is an older NLU system, and using a generative model (GPT) likely gives a more fluid conversation. We might use Lex for specific tasks or fallback if needed.
Amplify Gen 2 Advantages: Using Amplify Gen 2 (with the latest CLI v10+ and code-first workflow) will streamline our development. We can define our data models and auth in TypeScript, and Amplify will provision the AppSync API, DynamoDB tables, Cognito, etc., with infrastructure-as-code (CDK under the hood)
docs.amplify.aws
docs.amplify.aws
. This gives us the ability to have consistent environments (dev, prod) and use Git for versioning infra. Amplify also provides an admin UI and console which might be handy for managing content or viewing data during development. Furthermore, Amplify Hosting can deploy our Next.js app easily (including SSR support)
aws.amazon.com
 and even handle the CI/CD for the mobile app (though we might deploy mobile via app stores manually). The type-safe integration between front and back (GraphQL codegen giving us typed API calls in React) will reduce bugs and speed up development
aws.amazon.com
. Overall, Amplify’s serverless approach ensures we “never worry about scale” while keeping the stack in familiar React/TypeScript territory for our team
docs.amplify.aws
. External Services:
OpenAI (or similar LLM API): Initially, we plan to use the OpenAI GPT-4 or GPT-3.5 model via API for all AI conversations. This decision is because of the model’s superior language abilities and zero training requirement. The model will be prompted with a structured prompt that we design (including some system message like “You are an assistant for a real estate agent. Your goal is to qualify the lead and be friendly…” and including any known info about the lead/property). We’ll include the last few messages from the lead for context each time we call the API to generate the next response. Using OpenAI’s API will incur usage costs (e.g., ~$0.002 per 1K tokens for GPT-3.5, which is quite affordable – a typical conversation might be a few cents). We will monitor these costs to stay within budget. If needed, we could restrict the length of AI responses or use a cheaper model for long drip campaigns. As usage grows, we might evaluate running an open-source model on AWS to cut costs, but that comes with infrastructure complexity. For MVP and early stages, the reliability and quality of OpenAI is worth the cost.
Twilio (SMS/Voice) and Email API: For SMS and telephony, Twilio is a logical choice due to its ease of use and reliability. We’ll get a phone number (or multiple) from Twilio for our service. When the AI sends an SMS, our backend (Lambda) calls Twilio’s API to send it. When a lead replies, Twilio hits our webhook and we process it. Similarly for voice calls: Twilio can handle outbound dialing and piping audio to our system. Twilio even has a new “Conversation API” and ConversationRelay that can stream the call audio to a real-time inference service
twilio.com
twilio.com
. We might utilize that for low-latency AI voice conversations – Twilio’s guide on building an AI voice agent with a third-party LLM (like Mistral 7B) could inform our implementation
twilio.com
. If Twilio costs become an issue, alternatives include Amazon Connect (for calls, though more complex setup) or using lower-level SIP. But given our $100/mo budget target, Twilio’s pay-as-you-go should be fine (e.g., $0.0075 per SMS, and $0.01-$0.02 per voice minute – even 1,000 texts and 100 minutes of calls is under $20). For email, AWS Simple Email Service (SES) can be used, which is very cheap and easy to integrate via AWS SDK. SES will handle sending outbound emails (with proper DKIM/SPF so they aren’t flagged). This avoids needing another paid service for email.
Scalability & Security:
The chosen architecture is inherently scalable – all major components are serverless (Cognito, AppSync, Dynamo, Lambda, etc.) which automatically scale with demand. If our user base grows to many agents and thousands of leads, the system should scale without major changes (we might need to increase certain service quotas, but AWS handles the heavy lifting). Amplify’s use of CDK means we can extend the infrastructure as needed using any AWS service. Data security is paramount: all communication with clients will be over HTTPS (Amplify provisions TLS), and sensitive data (lead contacts, conversation content) will be stored securely in DynamoDB (which encrypts data at rest). We will enforce proper auth checks so one agent cannot ever access another’s data. Backups can be managed via DynamoDB backups or exporting data periodically to S3. For the AI data, we might consider not sending extremely sensitive info to OpenAI (and in privacy policy inform users that lead conversations are processed by AI provider). We’ll also implement logging and monitoring: CloudWatch for function logs, maybe an Amplify integrated monitoring to track API latency, etc. This ensures we can debug issues and maintain reliability (targeting high uptime, as agents may rely on this for every new lead). In summary, the tech stack is React/React Native frontends + AWS Amplify serverless backend + third-party AI/communication APIs, a combination that gives us full-stack type safety, fast development, and minimal DevOps overhead
aws.amazon.com
docs.amplify.aws
. It aligns well with the minimal budget, since we avoid running our own servers – we only pay for what we use on AWS and Twilio, keeping costs low when usage is low. The architecture is illustrated in the figure below, which is similar to a typical multi-tenant serverless app with Cognito for auth, AppSync API, Lambda functions, and DynamoDB for data storage: Figure: High-level architecture – The React web app and React Native mobile app authenticate via Amazon Cognito, interact with the AppSync GraphQL API (which uses DynamoDB for data and invokes Lambda for external calls). External services like OpenAI and Twilio are called from Lambda functions. This serverless design on AWS Amplify Gen 2 provides a scalable, secure backend for all tenants.